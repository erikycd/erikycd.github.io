---
title: "Modelos de visión generativos"
collection: teaching
type: "Workshop"
permalinuk: /teaching/2023-VMs
venue: "UNAM"
date: 2023-01-01
location: "CDMX, México"
language: "Español"
---

Este taller brinda a los participantes las habilidades y conocimientos necesarios para explorar los modelos de visión más comunes y aplicar técnicas intermedias en la generación artificial y transformación digital de imágenes.

![Illustration](/images/RB_T.png)

Módulo 1: Visión e imágenes en IA generativa
------
* Modelos generativos (VAEs, GANs, Diffusion)
* Herramientas generadoras
* Midjourney, DALLE, Stable Diffusion, Craiyon, CLIP

Módulo 2: Text-to-image
------
* Ingeniería de comandos (prompts) para imágenes
* Estilos y atributos 
* Prompt tunning
* Inpainting & outpainting

Módulo 3: Image-to-image
------
* Parametros iniciales
* Modificaciones del prompt

Módulo 4: Pattern-to-image
------
* Parametros iniciales
* Transfiriendo patrones
* Modificaciones del prompt

<p align="center">
  <img width="50%" src="https://github.com/erikycd/erikycd.github.io/blob/dc88d7175e17a4e73f09f0694cf32e82ecd3c146/images/pattern2img_1.jpg">
  <img width="50%" src="https://github.com/erikycd/erikycd.github.io/blob/dc88d7175e17a4e73f09f0694cf32e82ecd3c146/images/pattern2img_2.jpg">
</p>

Módulo Avanzado: Conectividad con Python
------
* Playground y API de OpenAI
* Interfaz y API de Stability
* Las plataformas Github y Huggingface
* Google Colab para generación y procesamiento de imágenes

Referencias:
------
* [DALL-E 2 prompt book](https://dallery.gallery/wp-content/uploads/2022/07/The-DALL%C2%B7E-2-prompt-book-v1.02.pdf)
* [Stable Diffusion prompt book](https://openart.ai/promptbook)
* [Website: 30 prompts for AI art to inspire you](https://mspoweruser.com/prompts-ai-art/)
* [Repositoio: Colab notebook Para el módulo avanzado](https://github.com/erikycd/Taller_visionM)
* Liu, J. (2023). How to imagine the world with text? From Text-to-image Generation View. Highlights in Science, Engineering and Technology, 39, 644-650. [https://doi.org/10.54097/hset.v39i.6619](https://doi.org/10.54097/hset.v39i.6619)
* Gafni, O., Polyak, A., Ashual, O., Sheynin, S., Parikh, D., & Taigman, Y. (2022). Make-A-Scene: Scene-Based Text-to-Image Generation with human Priors. arXiv (Cornell University). [https://doi.org/10.48550/arxiv.2203.13131](https://doi.org/10.48550/arxiv.2203.13131])
* Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., & Bengio, Y. (2014). Generative adversarial networks. arXiv (Cornell University). [https://doi.org/10.48550/arxiv.1406.2661](https://doi.org/10.48550/arxiv.1406.2661)
* Rombach, R. (2021, 20 diciembre). High-Resolution image synthesis with latent diffusion models. arXiv.org. [https://arxiv.org/abs/2112.10752](https://arxiv.org/abs/2112.10752)


